# -*- coding: utf-8 -*-
"""Teste GRU.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QflP6JY3fL9xmI8wvIhTBN5eVWMZoM-n

# Importando as bibliotecas
"""

import torchvision
import torch
import torch.nn as nn
from torchvision import datasets, transforms
import tqdm.notebook as tq
import zipfile
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from PIL import Image
from torch.utils.data import DataLoader, TensorDataset, Dataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
import torch.optim as optim
import copy
from scipy.stats import ks_2samp
from statsmodels.graphics.gofplots import qqplot_2samples
from statsmodels.tsa.stattools import acf

"""# Série temporal"""

from google.colab import drive
drive.mount('/content/drive')

#path = "/content/drive/MyDrive/Traffics.zip"
path = "/content/drive/MyDrive/Colab Notebooks/Traffics.zip"
zip_object = zipfile.ZipFile(file = path, mode = 'r')
zip_object.extractall('./')
zip_object.close()

#traffic = pd.read_csv('/content/drive/MyDrive/Traffics.csv')
traffic = pd.read_csv('/content/Traffics.csv')

traffic_data = traffic['GameBox_DL_Bitrate']

GameBox_DL_Bitrate = traffic['GameBox_DL_Bitrate']
GameBox_DL_Bitrate_size = int(len(GameBox_DL_Bitrate) * 0.2)
traffic_data = GameBox_DL_Bitrate[:GameBox_DL_Bitrate_size]

# Plotar a série temporal
plt.figure(figsize=(10, 6))
plt.plot(traffic_data, linestyle='-')
plt.title('Série Temporal')
plt.xlabel('time')
plt.ylabel('Valor')
plt.grid(True)
plt.show()

X = traffic_data.to_numpy()
X = np.array(traffic_data)

# Min-Max Scaling
min_value = np.min(X)
max_value = np.max(X)
scaled_serie = (X- min_value) / (max_value - min_value)

# Preparação dos dados em forma sequencial
def prepare_data(seq, n_steps):
    X, y = [], []
    for i in range(len(seq)):
        end_ix = i + n_steps
        if end_ix > len(seq)-1:
            break
        seq_x, seq_y = seq[i:end_ix], seq[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

n_steps = 10
# Criar dados de entrada e saída
X, y = prepare_data(scaled_serie, n_steps)

# Converter para tensores torch
X_tensor = torch.from_numpy(X).float()
y_tensor = torch.from_numpy(y).float()

# Separar dados em treinamento e teste (80% treinamento, 20% teste)
data_size = int(len(X) * 0.8)
X_train, X_test = X_tensor[:data_size], X_tensor[data_size:]
y_train, y_test = y_tensor[:data_size], y_tensor[data_size:]

y_test

"""# Definindo a rede GRU"""

class GRU(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):
        super(GRU, self).__init__()

       # Define o número de camadas e dos nós em cada camada
        self.num_layers = num_layers
        self.hidden_size= hidden_size

        # GRU camadas
        self.gru = nn.GRU(
            input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob
        )

        # Camadas totalmente conectadas
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # Inicialização do estado oculto para a primeira entrada com zeros
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size,device=x.device).requires_grad_()
        out, _ = self.gru(x, h0.detach())

        # Reformulando os outputs na forma de (batch_size, seq_length, hidden_size)
        # para que possa caber na camada totalmente conectada
        out = out[:, -1, :]
        out = self.fc(out)
        return out

# Inicializando o modelo LSTM
input_size = 1
hidden_size = 128
num_layers = 4
output_size = 1
dropout = 0.2


model = GRU(input_size, hidden_size, num_layers, output_size,dropout)


loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
num_epochs = 200

"""# Treinamento"""

# Listas para armazenar as séries temporais reais e preditas
real_series = []  # Série temporal real
predicted_series = []  # Série temporal predita
# Listas para armazenar a perda
train_losses = []
test_losses = []


# Treinamento da rede
for epoch in range(num_epochs):
    model.train()
    outputs = model(X_train.unsqueeze(-1)).squeeze()
    optimizer.zero_grad()
    loss = loss_function(outputs, y_train)
    loss.backward()
    optimizer.step()
    train_losses.append(loss.item())

    if (epoch + 1) % 100 == 0:
        print(f'Época [{epoch+1}/{num_epochs}], MSE Treinamento:  {loss.item(): .4f}')

    # Avaliação no conjunto de teste
    model.eval()
    with torch.no_grad():
        test_outputs = model(X_test.unsqueeze(-1)).squeeze()
        test_loss = loss_function(test_outputs, y_test)
        test_losses.append(test_loss.item())

        if (epoch + 1) % 100 == 0:
            print(f'Época [{epoch+1}/{num_epochs}], MSE Teste:  {test_loss.item(): .4f}')

    # Adicione as séries temporais reais e preditas nas listas correspondentes
    real_series.append(y_test.numpy())
    predicted_series.append(test_outputs.numpy())

# Converta as listas de NumPy arrays em tensores
real_series = torch.cat([torch.from_numpy(arr) for arr in real_series], dim=0)
predicted_series = torch.cat([torch.from_numpy(arr) for arr in predicted_series], dim=0)

# Plotando as funções de perda
plt.plot(train_losses, label='Train MSE')
plt.plot(test_losses, label='Test MSE')
plt.xlabel('Épocas')
plt.ylabel('MSE')
plt.legend()
plt.show()

# Plotar as séries temporais reais e preditas
plt.figure(figsize=(10, 6))
plt.plot(y_test, label='Real')
plt.plot(test_outputs, label='Predito')
plt.xlabel('Time')
plt.ylabel('Kbps')
plt.legend()
plt.title('Série Temporal Real vs Predita')
plt.show()

"""# Avaliando o Modelo

"""

# Previsões para dados de teste
test_predictions = test_outputs.numpy().flatten()
y_test_np = y_test.numpy().flatten()

# Calcular a média das previsões
media = np.mean(test_predictions)
mediareal = np.mean(y_test_np)
print(media)
print(mediareal)

# Calcular a mediana das previsões
mediana = np.median(test_predictions)
medianareal = np.median(y_test_np)
print(mediana)
print(medianareal)

# Calcular o desvio padrão
desvio_padrao_prediction = np.std(test_predictions)
desvio_padrao = np.std(y_test_np)
print(desvio_padrao_prediction)
print(desvio_padrao)

# Teste de Kolmogorov para comparar se a série temporal predita apresenta a mesma função de distribuição da série real
ks_statistic, p_value = ks_2samp(y_test.numpy(), test_predictions)
print(f'Teste Kolmogorov-Smirnov: {ks_statistic:.4f}, p-value: {p_value:.4f}')

# Gráfico Quantiles-to-Quantiles (QQ-plot) entre os valores preditos e os valores reais da série temporal
qqplot_2samples(y_test.numpy(), test_predictions, line='45')
plt.title('Quantiles-to-Quantiles (QQ-plot)')
plt.show()

# Erros quadráticos médios normalizados EQM1 e EQMN2
EQM1 = np.mean((y_test.numpy() - test_predictions) ** 2)
EQMN2 = EQM1 / np.var(y_test.numpy())
print(f'Normalized MSE (EQM1): {EQM1:.4f}')
print(f'Normalized MSE (EQMN2): {EQMN2:.4f}')

