# -*- coding: utf-8 -*-
"""FED Artigo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gexxuAcXsTar-Fi8BSWOdMRwl41IZJoH

# Importando as bibliotecas
"""

import torchvision
import torch
import torch.nn as nn
from torchvision import datasets, transforms
import tqdm.notebook as tq
import zipfile
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from PIL import Image
from torch.utils.data import DataLoader, TensorDataset, Dataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
import torch.optim as optim
import copy
from scipy.stats import ks_2samp
from statsmodels.graphics.gofplots import qqplot_2samples
from statsmodels.tsa.stattools import acf

"""# Serie temporal"""

from google.colab import drive
drive.mount('/content/drive')

path = "/content/drive/MyDrive/Traffics.zip"
#path = "/content/drive/MyDrive/Colab Notebooks/Traffics.zip"
zip_object = zipfile.ZipFile(file = path, mode = 'r')
zip_object.extractall('./')
zip_object.close()

#traffic = pd.read_csv('/content/drive/MyDrive/Traffics.csv')
traffic = pd.read_csv('/content/Traffics.csv')

traffic_data = traffic['GameBox_DL_Bitrate']

GameBox_DL_Bitrate = traffic['GameBox_DL_Bitrate']
GameBox_DL_Bitrate_size = int(len(GameBox_DL_Bitrate) * 0.2)
traffic_data = GameBox_DL_Bitrate[:GameBox_DL_Bitrate_size]

traffic_data

# Plotar a série temporal
plt.figure(figsize=(10, 6))
plt.plot(traffic_data, linestyle='-')
plt.title('Série Temporal')
plt.xlabel('time')
plt.ylabel('kbps')
plt.grid(True)
plt.show()

X = traffic_data.to_numpy()
X = np.array(traffic_data)

# Min-Max Scaling
min_value = np.min(X)
max_value = np.max(X)
scaled_serie = (X- min_value) / (max_value - min_value)

# Preparação dos dados em forma sequencial
def prepare_data(seq, n_steps):
    X, y = [], []
    for i in range(len(seq)):
        end_ix = i + n_steps
        if end_ix > len(seq)-1:
            break
        seq_x, seq_y = seq[i:end_ix], seq[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

n_steps = 24
# Criar dados de entrada e saída
X, y = prepare_data(scaled_serie, n_steps)

# Converter para tensores torch
X_tensor = torch.from_numpy(X).float()
y_tensor = torch.from_numpy(y).float()

# Separar dados em treinamento e teste (80% treinamento, 20% teste)
data_size = int(len(X) * 0.8)
X_train, X_test = X_tensor[:data_size], X_tensor[data_size:]
y_train, y_test = y_tensor[:data_size], y_tensor[data_size:]

def split_data_for_clients(data, num_clients):
    num_samples = len(data)
    samples_per_client = num_samples // num_clients
    client_data = []
    start_index = 0
    for i in range(num_clients):
        end_index = start_index + samples_per_client
        client_data.append(data[start_index:end_index])
        start_index = end_index
    return client_data

# Número de clientes
num_clients = 50

# Dividir os dados entre os clientes
client_data = split_data_for_clients(X_train, num_clients)

"""# Modelo de previsão"""

# Definir a arquitetura do modelo LSTM
class LSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

"""# Federated learning

"""

#Inicializando o modelo LSTM
input_size = 1
hidden_size = 128
num_layers = 4
output_size = 1

# Instanciar modelos LSTM para cada cliente
client_models = [LSTM(input_size, hidden_size, num_layers, output_size) for _ in range(num_clients)]

# Definir otimizador e função de perda
criterion = nn.MSELoss()
optimizers = [optim.Adam(model.parameters(), lr=0.001) for model in client_models]

# Listas para armazenar perda e acurácia por época
losses_per_epoch = []
accuracies_per_epoch = []

# Função de acurácia
def accuracy(y_pred, y_true, threshold):
    # Calcular a diferença absoluta entre as previsões e os valores verdadeiros
    absolute_diff = torch.abs(y_pred - y_true)
    # Calcular a acurácia como a porcentagem de amostras com diferença absoluta abaixo do limiar
    acc = torch.mean((absolute_diff < threshold).float())
    return acc.item()

"""# Treinamento"""

for epoch in range(200):
    epoch_losses = []
    epoch_accuracies = []
    for i, model in enumerate(client_models):
        model.train()
        optimizer = optimizers[i]
        X_client = client_data[i]
        y_client = y_train[:len(X_client)]

        optimizer.zero_grad()

        # Ajustar a forma dos dados para (batch_size, sequence_length, input_size)
        X_client = X_client.unsqueeze(-1)  # Adicionar uma dimensão para input_size

        # Forward pass
        output = model(X_client)

        # Calcular perda
        loss = criterion(output, y_client)
        epoch_losses.append(loss.item())

        # Calcular acurácia
        acc = accuracy(output, y_client, threshold=0.1)
        epoch_accuracies.append(acc)

        # Backward pass e atualização dos parâmetros
        loss.backward()
        optimizer.step()

    # Calcular média da perda e da acurácia por época
    epoch_loss_avg = np.mean(epoch_losses)
    epoch_acc_avg = np.mean(epoch_accuracies)

    # Armazenar perda e acurácia por época
    losses_per_epoch.append(epoch_loss_avg)
    accuracies_per_epoch.append(epoch_acc_avg)

    print(f"Epoch [{epoch+1}/200], Loss: {epoch_loss_avg:.4f}, Accuracy: {epoch_acc_avg:.4f}")

# Agregação dos modelos usando FEDAVG
aggregated_model = LSTM(input_size, hidden_size, num_layers, output_size)

for client_model in client_models:
    for aggregated_param, client_param in zip(aggregated_model.parameters(), client_model.parameters()):
        aggregated_param.data.add_(client_param.data / num_clients)

# Plotar perda por época
plt.figure(figsize=(10, 5))
plt.plot(losses_per_epoch, label='Loss', color='blue')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss per Epoch')
plt.legend()
plt.grid(True)
plt.show()

# Plotar acurácia por época
plt.figure(figsize=(10, 5))
plt.plot(accuracies_per_epoch, label='Accuracy', color='green')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy per Epoch')
plt.legend()
plt.grid(True)
plt.show()

"""# Avaliando o modelo

"""
